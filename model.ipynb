{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from constants import *\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeatTracker(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size=128, num_layers=2):\n",
    "        super(BeatTracker, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "                        nb, \n",
    "                        hidden_size, \n",
    "                        num_layers, \n",
    "                        bidirectional=True, \n",
    "                        #dropout=0.5,\n",
    "                        batch_first=True)\n",
    "        self.hid_to_beat = nn.Linear(2 * hidden_size, 2)\n",
    "        self.hidden = None #self.init_hidden()\n",
    "        \n",
    "        self.loss_function = nn.NLLLoss()\n",
    "        \n",
    "        self.lr = 0.001\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        h0 = torch.zeros(2 * self.num_layers, 1, self.hidden_size, device=device)\n",
    "        c0 = torch.zeros(2 * self.num_layers, 1, self.hidden_size, device=device)\n",
    "        return h0, c0\n",
    "    \n",
    "    def forward(self, spec):\n",
    "        x = self.lstm(spec)[0]\n",
    "        x = self.hid_to_beat(x)\n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "    \n",
    "    def set_lr(self, lr):\n",
    "        self.lr = lr\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = lr\n",
    "            \n",
    "    def learn(self, spec, onsets, isbeat):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self(spec)\n",
    "        output = output[onsets == 1]\n",
    "        target = isbeat[onsets == 1]\n",
    "        loss = self.loss_function(output, target)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        predic = torch.argmax(output, dim=1)\n",
    "        accuracy = torch.sum(predic == target).item() / predic.shape.numel()\n",
    "        \n",
    "        return loss.item(), accuracy\n",
    "    \n",
    "    def fit(self, dataset, batch_size=1, epochs=1):\n",
    "        loss_hist = np.zeros((epochs, -(-len(dataset) // batch_size)))\n",
    "        accu_hist = np.zeros((epochs, -(-len(dataset) // batch_size)))\n",
    "        for e in range(epochs):\n",
    "            start = time.time()\n",
    "            \n",
    "            dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            for i, (spec, onsets, isbeat) in enumerate(dataloader):\n",
    "                loss, accuracy = self.learn(spec, onsets, isbeat)\n",
    "                loss_hist[e, i] = loss\n",
    "                accu_hist[e, i] = accuracy\n",
    "            \n",
    "            end = time.time()\n",
    "            t = end - start\n",
    "            eta = str(datetime.timedelta(seconds=int(t * (epochs - e - 1))))\n",
    "            print(f'| Epoch: {e + 1:{len(str(epochs))}} | ', end='')\n",
    "            print(f'Loss: {np.mean(loss_hist[e]):7.4f} | ', end='')\n",
    "            print(f'Accuracy: {np.mean(accu_hist[e]):5.4f} | ', end='')\n",
    "            print(f'{t / len(dataloader):.2f} s/b | eta: {eta} |')\n",
    "        return loss_hist, accu_hist\n",
    "    \n",
    "    def predict(self, specs, onsets):\n",
    "        \"\"\"So far only works if batch_size = 1\"\"\"\n",
    "        with torch.no_grad():\n",
    "            output = model(specs)\n",
    "            output = output[onsets == 1]\n",
    "            pred_t = torch.argmax(output, dim=1)\n",
    "            onsets_frames = np.argwhere(onsets.squeeze(0) == 1).squeeze(0)\n",
    "            beats_frames = onsets_frames[pred_t == 1]\n",
    "            pred = torch.zeros_like(onsets)\n",
    "            pred[:, beats_frames] = 1\n",
    "        return pred\n",
    "    \n",
    "    def evaluate(self, specs, onsets, isbeat):\n",
    "        with torch.no_grad():\n",
    "            output = model(specs)\n",
    "            output = output[onsets == 1]\n",
    "            target = isbeat[onsets == 1]\n",
    "            predic = torch.argmax(output, dim=1)\n",
    "            \n",
    "            tn = torch.sum((predic == 0) & (target == 0)).item()\n",
    "            fp = torch.sum((predic == 1) & (target == 0)).item()\n",
    "            fn = torch.sum((predic == 0) & (target == 1)).item()\n",
    "            tp = torch.sum((predic == 1) & (target == 1)).item()\n",
    "        return tn, fp, fn, tp\n",
    "    \n",
    "    def evaluate_from_dataset(self, dataset):\n",
    "        dataloader = DataLoader(trainset, batch_size=len(trainset))\n",
    "        it = iter(dataloader)\n",
    "        specs, onsets, isbeat = it.next()\n",
    "        return self.evaluate(specs, onsets, isbeat)\n",
    "    \n",
    "    def freeze(self):\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    def unfreeze(self):\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "class ToTensor(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        spec_np, onsets_np, isbeat_np = sample\n",
    "        \n",
    "        spec = torch.tensor(spec_np.T)\n",
    "        \n",
    "        onsets = torch.zeros(spec.shape[0], dtype=torch.long)\n",
    "        isbeat = torch.zeros(spec.shape[0], dtype=torch.long)\n",
    "        \n",
    "        onsets[onsets_np] = 1\n",
    "        isbeat[onsets_np[isbeat_np == 1]] = 1\n",
    "        \n",
    "        return spec, onsets, isbeat\n",
    "    \n",
    "def beat_track(isbeat):\n",
    "    onset_envelope = isbeat.squeeze(0).numpy()\n",
    "    tempo, bt = librosa.beat.beat_track(\n",
    "                            sr=sr, \n",
    "                            onset_envelope=onset_envelope, \n",
    "                            hop_length=hl, \n",
    "                            tightness=800)\n",
    "    return bt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GTZAN import GTZAN\n",
    "from visualization import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a subset of the GTZAN dataset preprocessed using `preprocess-GTZAN` and split it into a train set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GTZAN(937, 'country', 20, getbeats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec, onsets, isbeat, beats = dataset[np.random.randint(len(dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showspec(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showdata(spec, onsets, isbeat, beats, duration=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BeatTracker(hidden_size=128, num_layers=2)\n",
    "print_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GTZAN(932, 'country', 20, ToTensor())\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "trainset, validset = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "print(f'Train size: {train_size}')\n",
    "print(f'Valid size: {valid_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion(*model.evaluate_from_dataset(validset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_hist, accu_hist = model.fit(trainset, batch_size=3, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion(*model.evaluate_from_dataset(validset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './data/model_02.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
